# text-modeling-system
This file includes the following components: 

Part I: Building an initial text model <br>
Part II: Saving and retrieving a text model <br>
Part III: Adding features to the model <br>
Part IV: Adding a Bayesian scoring algorithm <br>
Part V: Comparing Texts 

Specifically, I fed the initial text model articles from GQ and Cosmo so the model would begin to recognize each magazine's writing. I then ran additional articles from GQ and Cosmo through the model (articles that it had not yet seen) to test its accuracy - whether it correctly ranked those articles as being more similar to their correct publication. For fun, I ran articles from other publications as well as my own writing through the model to see which publication - GQ or Cosmo - the model scored the writing as being more similar to. 

For further description and my results report, check out my reflection below! 




Battle of the Sexes: Cosmo Versus GQ

For my original bodies of text, I chose articles from Cosmopolitan magazine’s website and articles from GQ magazine’s website. Since Cosmo targets women and GQ targets men, I thought it’d be fun to compare other, less obviously gendered publications against them to determine whether the other publications were more like Cosmo (and more likely to target women) or more like GQ (and more likely to target men). The specific bodies I compared against the originals include articles from Rolling Stone magazine and Nylon magazine, my own writing (a film review I wrote last year in COM 201), and a story from The New Yorker. I also compared an extra Cosmo and extra GQ article - each of which I’d withheld when building my original Cosmo and GQ models - to test whether they were rated as being most similar to the publication they actually came from. 

While some of my comparison results aligned with my expectations, others did not. For instance, the similarity between the extra Cosmo article and Cosmo (-1954.0005511835834) did reflect that article as being more similar to Cosmo than to GQ (of which the similarity was -2065.9136411651366). However, the extra GQ article had, by a slim margin, more similarity with Cosmo (score of -1507.0205134557807) than it did with GQ (score of -1578.124051259954). In terms of the other, outside writing samples, Rolling Stone was more similar to Cosmo (score of -17611.648232827247) than to GQ (score of -18148.952280754). Although by a smaller margin, Nylon was also more similar to Cosmo (score of -638.900384772987) than to GQ (score of -673.4875409755381). Also by slim margins, my writing and The New Yorker proved closer to Cosmo (scores of -4054.703262061179 and -18289.064879292724 respectively) than to GQ (scores of -4212.822005281027 and -18993.09443422856 respectively). At face value, these scores indicate that Rolling Stone, Nylon and The New Yorker are more similar to Cosmo - and thus, may lean toward targeting a female audience as opposed to GQ’s male audience. And, they indicate that I may well be better suited to write for Cosmo in my career as a journalist than for GQ!

While I anticipated that Rolling Stone and Nylon could go either way in terms of what publication and gender they lean toward, I definitely didn’t expect The New Yorker to be closer to Cosmo; my initial impression of GQ is that it has a higher ratio of ‘serious,’ investigative articles, whereas Cosmo dwells heavily on superficial sex tips. On the other hand, that the extra GQ article had a closer similarity with Cosmo than GQ could have just been a fluke occurrence - magazines feature so much variety of topic and style that that one particular article could well be more like something you’d normally expect from Cosmo than GQ. I think the basic functionality of my text classification works; it’s making the comparisons based on the texts it has to work with. Yet, to get the most fair and accurate classifications, I think one area through which I could improve my text classification program would be through reconsidering the texts I built my original models with. For one thing, both GQ and Cosmo have many writers, male and female. Their varying writing styles may be problematic in that more range within a model means more chance an outside article could match that publication; the model’s specificity decreases. Also, both magazines have many sections - style, music, relationships, and beyond. Again, having the models both pull from all the varying sections rather than sticking to just, say, the music sections from Cosmo and GQ makes the models broader rather than specific to the publication; focusing in on how each magazine does one section could serve as a better sample for the greater publication. One thing I did try to account for was the fact that Cosmo articles tended to be longer than the GQ ones; for that reason, I think Cosmo had more words for outside bodies to match up with. To compensate, I put an extra file in my original GQ model, building that model with 4 shorter files versus adding 3 longer files to the Cosmo model. Yet, I think this could be expanded. The more files in the original models, the more accurate a picture those models are going to create of their text bodies. So, adding even more stories to both - yet still ensuring that the cumulative amount of text being fed into both models is about even - could only help make my program more accurate! 
